{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Keypoint Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_directory = \"/data/\"\n",
    "training_filename = \"training.csv\"\n",
    "batch_size = 128\n",
    "num_epochs=500\n",
    "dropout =False\n",
    "use_ConvNet = True\n",
    "xavier_weights = True\n",
    "learning_amount= .01\n",
    "momentum_amount = 0.9\n",
    "learn_decay = False\n",
    "momentum_inc = False\n",
    "opt = \"SGD\"\n",
    "\n",
    "model_name = \"ConvNet\" + str(learning_amount) + \"_\" + str(num_epochs) + opt\n",
    "model_filename = model_name + \".ckpt\"\n",
    "model_directory = os.getcwd() + \"/FinalModels/\" + model_name\n",
    "model_path = model_directory + \"/\" + model_filename\n",
    "\n",
    "# Images are 96 x 96 grayscale with 15 features using (x, y) coordinates\n",
    "image_size = 96\n",
    "num_channels = 1 # grayscale\n",
    "num_classes = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class MiniBatcher(object):\n",
    "    def __init__(self, batch_size, shuffle=False, seed=43):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random = np.random.RandomState(seed)\n",
    "\n",
    "    def __call__(self, X, y=None):\n",
    "        if self.shuffle:\n",
    "            _shuffle_arrays([X, y] if y is not None else [X], self.random)\n",
    "        self.X, self.y = X, y\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def __iter__(self):\n",
    "        bs = self.batch_size\n",
    "        for i in range((self.n_samples + bs - 1) // bs):\n",
    "            sl = slice(i * bs, (i + 1) * bs)\n",
    "            Xb = _sldict(self.X, sl)\n",
    "            if self.y is not None:\n",
    "                yb = _sldict(self.y, sl)\n",
    "            else:\n",
    "                yb = None\n",
    "            yield self.transform(Xb, yb)\n",
    "            \n",
    "\n",
    "    @property\n",
    "    def n_samples(self):\n",
    "        X = self.X\n",
    "        if isinstance(X, dict):\n",
    "            return len(list(X.values())[0])\n",
    "        else:\n",
    "            return len(X)\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        return Xb, yb\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = dict(self.__dict__)\n",
    "        for attr in ('X', 'y',):\n",
    "            if attr in state:\n",
    "                del state[attr]\n",
    "        return state\n",
    "    \n",
    "def _shuffle_arrays(arrays, random):\n",
    "    rstate = random.get_state()\n",
    "    for array in arrays:\n",
    "        if isinstance(array, dict):\n",
    "            for v in list(array.values()):\n",
    "                random.set_state(rstate)\n",
    "                random.shuffle(v)\n",
    "        else:\n",
    "            random.set_state(rstate)\n",
    "            random.shuffle(array)\n",
    "            \n",
    "def _sldict(arr, sl):\n",
    "    if isinstance(arr, dict):\n",
    "        return {k: v[sl] for k, v in arr.items()}\n",
    "    else:\n",
    "        return arr[sl]\n",
    "    \n",
    "class AugBatcher(MiniBatcher):\n",
    "\n",
    "    def __init__(self, batch_size, shuffle=False, seed=1, add_flips=False, add_rotate=False):\n",
    "        super(AugBatcher, self).__init__(batch_size, shuffle=False, seed=1)\n",
    "        self.add_flips = add_flips\n",
    "        self.add_rotate = add_rotate\n",
    "        self.flip_indices = [\n",
    "        (0, 2), (1, 3),\n",
    "        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "        (22, 24), (23, 25),\n",
    "        ]\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(AugBatcher, self).transform(Xb, yb)\n",
    "\n",
    "        Xb = copy.deepcopy(Xb)\n",
    "        yb = copy.deepcopy(yb)\n",
    "        if self.add_flips:\n",
    "        # Flip half of the images in this batch at random:\n",
    "            bs = Xb.shape[0]\n",
    "            indices = np.random.choice(bs, int(bs / 2), replace=False)\n",
    "            Xb[indices] = Xb[indices, :, ::-1, :]\n",
    "\n",
    "            if yb is not None:\n",
    "                # Horizontal flip of all x coordinates:\n",
    "                yb[indices, ::2] = yb[indices, ::2] * -1\n",
    "\n",
    "                # Swap places, e.g. left_eye_center_x -> right_eye_center_x\n",
    "                for a, b in self.flip_indices:\n",
    "                    yb[indices, a], yb[indices, b] = (\n",
    "                        yb[indices, b], yb[indices, a])\n",
    "        \n",
    "        #print(\"Before: \" + str(Xb[0]))\n",
    "        if self.add_rotate:\n",
    "            for i in range(0, len(Xb)): \n",
    "                if random.uniform(0, 1) > .5:\n",
    "                    angle = random.uniform(-5, 5)\n",
    "                    Xb[i] = np.reshape(misc.imrotate(np.reshape(Xb[i], [image_size, image_size]), -angle), [1, image_size, image_size, 1]) / 255\n",
    "                    for j in range(0, 30, 2):\n",
    "                        yb[i, j], yb[i, j+1] = rotatePoint((0, 0), (yb[i, j], yb[i, j+1]), angle)\n",
    "        \n",
    "        #print(\"After: \" + str(Xb[0]))\n",
    "        return Xb, yb\n",
    "\n",
    "def rotatePoint(centerPoint,point,angle):\n",
    "    angle = math.radians(angle)\n",
    "    temp_point = point[0]-centerPoint[0] , point[1]-centerPoint[1]\n",
    "    temp_point = ( temp_point[0]*math.cos(angle)-temp_point[1]*math.sin(angle) , temp_point[0]*math.sin(angle)+temp_point[1]*math.cos(angle))\n",
    "    temp_point = temp_point[0]+centerPoint[0] , temp_point[1]+centerPoint[1]\n",
    "    return temp_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep = ' '))\n",
    "    df = df.dropna()\n",
    "\n",
    "    values = np.vstack(df['Image'].values) / 255.\n",
    "    values = values.astype(np.float32)\n",
    "\n",
    "    labels = df[df.columns[:-1]].values\n",
    "    labels = (labels - 48) / 48  \n",
    "    values, labels = shuffle(values, labels, random_state=3)  \n",
    "    labels = labels.astype(np.float32)\n",
    "\n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(0.5) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3937dbdd844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2037\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m         cv = StratifiedShuffleSplit(stratify, test_size=test_size,\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 126\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(0.5) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "image_values, image_labels = loadData(os.getcwd() + data_directory + training_filename)\n",
    "image_values = np.reshape(image_values, [-1, image_size, image_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, validation_data, train_labels, validation_labels = train_test_split(image_values, image_labels, test_size = 0.3)\n",
    "valid_data, test_data, valid_labels, test_labels = train_test_split(validation_data, validation_labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFullyConnectedLayer(x_input, width):\n",
    "    # createFullyConnectedLayer generates a fully connected layer in the session graph\n",
    "    # \n",
    "    # x_input - output from previous layer\n",
    "    # width - width of the layer (eg for a 10 class output you need to end with a 10 width layer\n",
    "    #\n",
    "    # returns fully connected layer in graph\n",
    "    #\n",
    "    if(xavier_weights):\n",
    "        print(\"Xavier Weights\")\n",
    "        weights = tf.get_variable('weights', shape=[x_input.get_shape()[1], width],\n",
    "                             initializer = tf.contrib.layers.xavier_initializer())\n",
    "    else:\n",
    "        print(\"Zero Weights\")\n",
    "        weights = tf.get_variable('weights', shape=[x_input.get_shape()[1], width],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "        \n",
    "    biases = tf.get_variable('biases', shape=[width], initializer=tf.constant_initializer(0))\n",
    "     \n",
    "    matrix_multiply = tf.matmul(x_input, weights)\n",
    "    \n",
    "    total_parameters = x_input.get_shape()[1] * width + width\n",
    "    \n",
    "    print(\"Created Fully Connected Layer: Input\" + str(x_input.get_shape()) + \" Parameters(\" + str(total_parameters) + \")\")\n",
    "    \n",
    "    return tf.nn.bias_add(matrix_multiply, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createConvolutionLayer(x_input, kernel_size, features, depth):\n",
    "    # createConvolutionLayer generates a convolution layer in the session graph\n",
    "    # by assigning weights, biases, convolution and relu function\n",
    "    #\n",
    "    # x_input - output from the previous layer\n",
    "    # kernel_size - size of the feature kernels\n",
    "    # depth - number of feature kernels\n",
    "    #\n",
    "    # returns convolution layer in graph\n",
    "    #\n",
    "    if xavier_weights:\n",
    "        print(\"Xavier Weights\")\n",
    "        weights = tf.get_variable('weights', shape=[kernel_size, kernel_size, features, depth],\n",
    "                             initializer = tf.contrib.layers.xavier_initializer())\n",
    "    else:\n",
    "        print(\"Zero Weights\")\n",
    "        weights = tf.get_variable('weights', shape=[kernel_size, kernel_size, features, depth],\n",
    "                             initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    biases = tf.get_variable('biases', shape=[depth], initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    convolution = tf.nn.conv2d(x_input, weights, strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    added = tf.nn.bias_add(convolution, biases)\n",
    "    \n",
    "    total_parameters = kernel_size*kernel_size*features*depth + depth\n",
    "    print(\"Created Convolution Layer: Input\" + str(x_input.get_shape()) + \" Parameters(\" + str(total_parameters) + \")\")\n",
    "    \n",
    "    return tf.nn.relu(added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createLinearRectifier(x_input):\n",
    "    # createLinearRectifier generates a ReLu in the session graph\n",
    "    # \n",
    "    # The reason this exists is due to the last fully connected layer not needing a relu while others do\n",
    "    # x_input - output from previous layer\n",
    "    # width - width of the layer\n",
    "    #\n",
    "    # returns ReLU in graph\n",
    "    # \n",
    "    print(\"Created RELU Activation Function\")\n",
    "    return tf.nn.relu(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPoolingLayer(x_input, kernel_size):\n",
    "    # createPoolingLayer generates a pooling layer in the session graph\n",
    "    # \n",
    "    # The reason this exists is due to the last fully connected layer not needing a relu while others do\n",
    "    # x_input - output from previous layer\n",
    "    # kernel_size - size of the kernel\n",
    "    #\n",
    "    # returns pooling layer in graph\n",
    "    # \n",
    "    \n",
    "    print(\"Created Pooling Layer: Downsample:\" + str(kernel_size))\n",
    "    return tf.nn.max_pool(x_input, ksize=[1, kernel_size, kernel_size, 1], strides=[1,kernel_size,kernel_size, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSimpleNetwork(model_input):\n",
    "    with tf.variable_scope('input'):\n",
    "        input_layer = tf.reshape(model_input, [-1, image_size * image_size])\n",
    "    with tf.variable_scope('hidden'):\n",
    "        hidden_fully_connected_layer = createFullyConnectedLayer(input_layer, 100)\n",
    "    relu_layer = createLinearRectifier(hidden_fully_connected_layer)\n",
    "    with tf.variable_scope('out'):\n",
    "        model_output = createFullyConnectedLayer(relu_layer, 30)\n",
    "        \n",
    "    print(\"Simple Network Created\")\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createConvNetwork(x_input, is_train):\n",
    "    # Define convolution layers\n",
    "    with tf.variable_scope('conv1'):\n",
    "        convolution_layer1 = createConvolutionLayer(x_input, 3, 1, 32)\n",
    "        pooling_layer1 = createPoolingLayer(convolution_layer1, 2)\n",
    "        # Determine if used for training or test/validate. Only use dropout for training\n",
    "        pooling_layer1 = tf.cond(is_train, lambda: tf.nn.dropout(pooling_layer1, keep_prob = 0.9 if dropout else 1.0), lambda: pooling_layer1)\n",
    "    with tf.variable_scope('conv2'):\n",
    "        convolution_layer2 = createConvolutionLayer(pooling_layer1, 2, 32, 64)\n",
    "        pooling_layer2 = createPoolingLayer(convolution_layer2, 2)\n",
    "        # Determine if used for training or test/validate. Only use dropout for training\n",
    "        pooling_layer2 = tf.cond(is_train, lambda: tf.nn.dropout(pooling_layer2, keep_prob = 0.8 if dropout else 1.0), lambda: pooling_layer2)\n",
    "    with tf.variable_scope('conv3'):\n",
    "        convolution_layer3 = createConvolutionLayer(pooling_layer2, 2, 64, 128)\n",
    "        pooling_layer3 = createPoolingLayer(convolution_layer3, 2)\n",
    "        # Determine if used for training or test/validate. Only use dropout for training\n",
    "        pooling_layer3 = tf.cond(is_train, lambda: tf.nn.dropout(pooling_layer3, keep_prob = 0.7 if dropout else 1.0), lambda: pooling_layer3)\n",
    "    \n",
    "    # Flatten output to connect to fully connected layers\n",
    "    print(\"fc: input size before flattening: \" + str(pooling_layer3.get_shape()))\n",
    "    pooling_layer3_shape = pooling_layer3.get_shape().as_list()\n",
    "    pooling_layer3_flattened = tf.reshape(pooling_layer3, [-1, pooling_layer3_shape[1] * pooling_layer3_shape[2] * pooling_layer3_shape[3]])\n",
    "    \n",
    "    # Define fully connected layers\n",
    "    with tf.variable_scope('fc1'):\n",
    "        fully_connected_layer1 = createFullyConnectedLayer(pooling_layer3_flattened, 1000)\n",
    "        fully_connected_relu1 = createLinearRectifier(fully_connected_layer1)\n",
    "        fully_connected_relu1 = tf.cond(is_train, lambda: tf.nn.dropout(fully_connected_relu1, keep_prob = 0.5 if dropout else 1.0), lambda: fully_connected_relu1)\n",
    "    with tf.variable_scope('fc2'):\n",
    "        fully_connected_layer2 = createFullyConnectedLayer(fully_connected_relu1, 1000)\n",
    "        fully_connected_relu2 = createLinearRectifier(fully_connected_layer2)\n",
    "    with tf.variable_scope('out'):\n",
    "        output = createFullyConnectedLayer(fully_connected_relu2, 30)\n",
    "        print(\"out: \" + str(output.get_shape()))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(train_images, train_labels, valid_images, valid_labels, test_images, test_labels, num_epochs, batch_size, model_name, flip, rotate):\n",
    "    start = time.time()\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    time_list = []\n",
    "    epoch_list = []\n",
    "    print(\"TRAINING: \" + model_name)\n",
    "\n",
    "    with tf.Session(graph = graph) as session:\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        #if os.path.exists(model_directory):\n",
    "        #    print(\"Loading model...\")\n",
    "        #    load_path = saver.restore(session, model_path)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            batch = AugBatcher(batch_size=batch_size, shuffle=True, add_flips=flip, add_rotate=rotate)\n",
    "            for batch_data, batch_labels in batch(train_images, train_labels):\n",
    "                feed_dict = {model_input: batch_data, model_output: batch_labels, model_training: True}\n",
    "                # train model\n",
    "                session.run([model_optimizer], feed_dict = feed_dict)\n",
    "\n",
    "            #Store train and validation losses\n",
    "            if epoch % 10 == 0:\n",
    "                train_loss = getLoss(train_images, train_labels, session)\n",
    "                train_loss_list.append(train_loss)\n",
    "                valid_loss = getLoss(valid_images, valid_labels, session)\n",
    "                valid_loss_list.append(valid_loss)\n",
    "\n",
    "                current_time = time.time() - start\n",
    "                hours, minutes, seconds = getTime(current_time)\n",
    "                if learn_decay:\n",
    "                    print(\"Epoch[%4d]\" % epoch + \"%d\" % hours + \":%2d\" % minutes + \":%2d \" % seconds + \"%f \" % train_loss + \" %f\" % valid_loss + \" %f\" % learning_rate.eval())\n",
    "                else:\n",
    "                    print(\"Epoch[%4d]\" % epoch + \"%d\" % hours + \":%2d\" % minutes + \":%2d \" % seconds + \"%f \" % train_loss + \" %f\" % valid_loss + \" %f\" % learning_rate)\n",
    "                \n",
    "                time_list.append(current_time)\n",
    "                epoch_list.append(epoch)\n",
    "\n",
    "            if epoch % 300 == 0:\n",
    "                if not os.path.exists(model_directory):\n",
    "                    os.mkdir(model_directory)\n",
    "                print(\"Saving Model...\")    \n",
    "                save_path = saver.save(session, model_path)\n",
    "            # Evaluate on test dataset.\n",
    "            step = session.run(increment_global_step_op)\n",
    "        test_loss = getLoss(test_images, test_labels, session)\n",
    "        print(\" Test score: %.3f (loss = %.8f)\" % (np.sqrt(test_loss) * 48.0, test_loss)) #RMSE\n",
    "        if not os.path.exists(model_directory):\n",
    "            os.mkdir(model_directory)\n",
    "        print(\"Saving Model...\")\n",
    "        save_path = saver.save(session, model_path)\n",
    "        saveModelHistory(epoch_list, time_list, train_loss_list, valid_loss_list, [test_loss], 'Loss3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLoss(values, labels, session):\n",
    "    loss_ = []\n",
    "    batch = MiniBatcher(batch_size = 128)\n",
    "    for batch_values, batch_labels in batch(values, labels):\n",
    "        loss_batch = session.run(model_loss, feed_dict = {model_input : batch_values, model_output : batch_labels, model_training : False})\n",
    "        loss_.append(loss_batch)\n",
    "    return np.mean(loss_)\n",
    "\n",
    "def getTime(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    \n",
    "    return h, m, s\n",
    "\n",
    "def saveModelHistory(epoch_list, time_list, train_loss_list, valid_loss_list, test_loss, name):\n",
    "    df = pd.DataFrame({'Epochs' : epoch_list, 'Time' :  time_list, 'Train': train_loss_list, 'Valid' : valid_loss_list})\n",
    "    df2 = pd.DataFrame({'Test:' : test_loss})\n",
    "    df = pd.concat([df,df2], axis=1)\n",
    "    writer = pd.ExcelWriter(model_path + name + '.xlsx', engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xavier Weights\n",
      "Created Convolution Layer: Input(?, 96, 96, 1) Parameters(320)\n",
      "Created Pooling Layer: Downsample:2\n",
      "Xavier Weights\n",
      "Created Convolution Layer: Input(?, 48, 48, 32) Parameters(8256)\n",
      "Created Pooling Layer: Downsample:2\n",
      "Xavier Weights\n",
      "Created Convolution Layer: Input(?, 24, 24, 64) Parameters(32896)\n",
      "Created Pooling Layer: Downsample:2\n",
      "fc: input size before flattening: (?, 12, 12, 128)\n",
      "Xavier Weights\n",
      "Created Fully Connected Layer: Input(?, 18432) Parameters(18433000)\n",
      "Created RELU Activation Function\n",
      "Xavier Weights\n",
      "Created Fully Connected Layer: Input(?, 1000) Parameters(1001000)\n",
      "Created RELU Activation Function\n",
      "Xavier Weights\n",
      "Created Fully Connected Layer: Input(?, 1000) Parameters(30030)\n",
      "out: (?, 30)\n",
      "Using SGD Optimizer\n",
      "TRAINING: ConvNet0.01_500SGD\n",
      "Epoch[   0]0: 0: 4 0.124364  0.125541 0.010000\n",
      "Saving Model...\n",
      "Epoch[  10]0: 0:35 0.008346  0.008109 0.010000\n",
      "Epoch[  20]0: 1: 7 0.007631  0.007375 0.010000\n",
      "Epoch[  30]0: 1:40 0.007287  0.007041 0.010000\n",
      "Epoch[  40]0: 2:12 0.006988  0.006753 0.010000\n",
      "Epoch[  50]0: 2:44 0.006736  0.006495 0.010000\n",
      "Epoch[  60]0: 3:16 0.006519  0.006277 0.010000\n",
      "Epoch[  70]0: 3:50 0.006315  0.006090 0.010000\n",
      "Epoch[  80]0: 4:21 0.006145  0.005919 0.010000\n",
      "Epoch[  90]0: 4:52 0.005987  0.005766 0.010000\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    model_input = tf.placeholder(tf.float32, shape=(None, image_size, image_size, 1))\n",
    "    model_output = tf.placeholder(tf.float32, shape=(None, 30))\n",
    "    model_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    current_epoch = tf.Variable(0, trainable=False)\n",
    "    increment_global_step_op = tf.assign(current_epoch, current_epoch+1)\n",
    "    \n",
    "    #Parameters\n",
    "\n",
    "    if learn_decay:\n",
    "        print(\"learn decay on\")\n",
    "        learning_rate = tf.train.exponential_decay(learning_amount, current_epoch, decay_steps=num_epochs, decay_rate=.9)\n",
    "    else:\n",
    "        learning_rate = learning_amount\n",
    "    if momentum_inc:\n",
    "        m_min = 0.9\n",
    "        m_max = 0.99\n",
    "        print(\"momentum increase on\")\n",
    "        momentum_rate = m_min + (m_max - m_min) * (current_epoch / num_epochs)\n",
    "    else:\n",
    "        momentum_rate = momentum_amount\n",
    "    # get model\n",
    "    if dropout:\n",
    "        print(\"Dropout on\")\n",
    "    \n",
    "    if(use_ConvNet):\n",
    "        with tf.variable_scope(model_name):\n",
    "            model_predictions = createConvNetwork(model_input, model_training)\n",
    "    else:\n",
    "        with tf.variable_scope(model_name):\n",
    "            model_predictions = createSimpleNetwork(model_input)\n",
    "    \n",
    "    model_loss = tf.reduce_mean(tf.square(model_predictions - model_output))\n",
    "    \n",
    "    if opt == \"MOM\":\n",
    "        print(\"Using Momentum Optimizer\")\n",
    "        model_optimizer = tf.train.MomentumOptimizer(learning_rate, momentum_rate, use_nesterov=True).minimize(model_loss)\n",
    "    elif opt == \"ADAM\":\n",
    "        print(\"Using ADAM Optimizer\")\n",
    "        model_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\n",
    "    else:\n",
    "        print(\"Using SGD Optimizer\")\n",
    "        model_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model_loss)\n",
    "\n",
    "trainModel(train_data, train_labels, valid_data, valid_labels, test_data, test_labels, num_epochs, batch_size, model_name, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(x_valid)):\n",
    "    for j in range(len(x_test)):\n",
    "        if np.array_equal(x_valid[i], x_test[j]):\n",
    "            print(\"CROSS CONTAMINATED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions and output to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on C:\\Users\\sethd\\CNNTutorials\\7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD/ConvNet0.001_500SGD.ckpt: Not found: FindFirstFile failed for: C:/Users/sethd/CNNTutorials/7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD : The system cannot find the path specified.\r\n\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_4/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_106_save_1/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-2f5a379e5031>\", line 3, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1000, in __init__\n    self.build()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on C:\\Users\\sethd\\CNNTutorials\\7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD/ConvNet0.001_500SGD.ckpt: Not found: FindFirstFile failed for: C:/Users/sethd/CNNTutorials/7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD : The system cannot find the path specified.\r\n\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_4/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_106_save_1/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on C:\\Users\\sethd\\CNNTutorials\\7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD/ConvNet0.001_500SGD.ckpt: Not found: FindFirstFile failed for: C:/Users/sethd/CNNTutorials/7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD : The system cannot find the path specified.\r\n\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_4/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_106_save_1/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2f5a379e5031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mload_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[1;31m#p = session.run(model_predictions, feed_dict={model_input: np.reshape(new_image, [1, 96, 96, 1]), model_training:False})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1388\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on C:\\Users\\sethd\\CNNTutorials\\7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD/ConvNet0.001_500SGD.ckpt: Not found: FindFirstFile failed for: C:/Users/sethd/CNNTutorials/7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD : The system cannot find the path specified.\r\n\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_4/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_106_save_1/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-50-2f5a379e5031>\", line 3, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1000, in __init__\n    self.build()\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1030, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 624, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 361, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 200, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 441, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\sethd\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on C:\\Users\\sethd\\CNNTutorials\\7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD/ConvNet0.001_500SGD.ckpt: Not found: FindFirstFile failed for: C:/Users/sethd/CNNTutorials/7. FacialFeatureDetection_Tutorial/FinalModels/ConvNet0.001_500SGD : The system cannot find the path specified.\r\n\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_4/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_106_save_1/RestoreV2_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    load_path = saver.restore(session, model_path)\n",
    "    #p = session.run(model_predictions, feed_dict={model_input: np.reshape(new_image, [1, 96, 96, 1]), model_training:False})\n",
    "    p = session.run(model_predictions, feed_dict={model_input: test_data, model_training:False})\n",
    "    #loss = session.run(loss_function, feed_dict={tf_x_batch: x_valid, y_output: y_valid, is_training:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-89d839d3508b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKUAAACGCAYAAAC8E0pCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAcRJREFUeJzt1TFOQmEQRtH3G5cAtW//a4FFUOsexp4GMEFv8Jz6K6a4\nyayZ2aDk7a8PgGuiJEeU5IiSHFGSI0pyREmOKMkRJTnvj4wPh8Ps+/6kU3h15/P5a2aOt3YPRbnv\n+3Y6nX5+Ff/aWutyz877JkeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmi\nJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmO\nKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGS\nI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU\n5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkRJTmiJEeU5IiSHFGSI0pyREmOKMkR\nJTmiJEeU5IiSHFGSI0pyREmOKMlZM3P/eK3PbdsuzzuHF/cxM8dbo4eihN/gfZMjSnJESY4oyREl\nOaIkR5TkiJIcUZLzDSAoGq3i3BfHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e47709828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(15, 150))\n",
    "\n",
    "for i in range(300):\n",
    "    axis = fig.add_subplot(60, 5, i + 1, xticks=[], yticks=[])\n",
    "    img = x_test[i]\n",
    "    img = img.reshape(96, 96)\n",
    "    y = y_test[i]\n",
    "    y2 = p[i]\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    # Actual labels\n",
    "    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10, color='red')\n",
    "    # Predicted labels\n",
    "    axis.scatter(y2[0::2] * 48 + 48, y2[1::2] * 48 + 48, marker='x', s=10, color='lime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "#fig.subplots_adjust(\n",
    "#    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(25):\n",
    "    axis = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
    "    img = new_image\n",
    "    img = img.reshape(96, 96)\n",
    "    #y = y_test[i]\n",
    "    y2 = p[0]\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    # Actual labels\n",
    "    #axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10, color='red')\n",
    "    # Predicted labels\n",
    "    axis.scatter(y2[0::2] * 48 + 48, y2[1::2] * 48 + 48, marker='x', s=10, color='lime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "#fig.subplots_adjust(\n",
    "#    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(25):\n",
    "    axis = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
    "    img = new_image\n",
    "    img = img.reshape(96, 96)\n",
    "    #y = y_test[i]\n",
    "    y2 = p[0]\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    # Actual labels\n",
    "    #axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10, color='red')\n",
    "    # Predicted labels\n",
    "    axis.scatter(y2[0::2] * 48 + 48, y2[1::2] * 48 + 48, marker='x', s=10, color='lime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert New Image and Predict Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "new_image = mpimg.imread('sethdecker6.jpg')\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "#new_image = rgb2gray(new_image)\n",
    "plt.imshow(new_image)\n",
    "\n",
    "new_image = new_image / 255\n",
    "\n",
    "plt.imshow(new_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for Checking Model Robustness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "flip = True\n",
    "dropout = True\n",
    "use_ConvNet = True\n",
    "num_epochs = 1000\n",
    "\n",
    "learning_amount= 0.12\n",
    "momentum_amount = 0.9\n",
    "learn_decay = True\n",
    "momentum_inc = True\n",
    "opt = \"MOM\"\n",
    "\n",
    "skf = KFold(n=len(image_values), n_folds=kfolds)\n",
    "i = 0\n",
    "for train_index, test_index in skf:\n",
    "\n",
    "    learning_rate = learning_amount\n",
    "    momentum_rate = momentum_rate\n",
    "    train_images1 = np.array([image_values[i] for i in train_index])\n",
    "    train_labels1 = np.array([image_labels[i] for i in train_index])\n",
    "    \n",
    "    test_images = np.array([image_values[i] for i in test_index])\n",
    "    test_labels = np.array([image_labels[i] for i in test_index])\n",
    "    \n",
    "    \n",
    "    print(train_images1[0].shape)\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        noise = False\n",
    "        bright= False\n",
    "        rotate = False\n",
    "\n",
    "        model_input = tf.placeholder(tf.float32, shape=(None, image_size, image_size, 1))\n",
    "        model_output = tf.placeholder(tf.float32, shape=(None, 30))\n",
    "        model_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        current_epoch = tf.Variable(0, trainable=False)\n",
    "        increment_global_step_op = tf.assign(current_epoch, current_epoch+1)\n",
    "        #Define Parameters\n",
    "\n",
    "\n",
    "        if learn_decay:\n",
    "            print(\"learn decay on\")\n",
    "            learning_rate = tf.train.exponential_decay(learning_amount, current_epoch, decay_steps=num_epochs, decay_rate=0.9)\n",
    "        else:\n",
    "            learning_rate = learning_amount\n",
    "        if momentum_inc:\n",
    "            m_min = 0.9\n",
    "            m_max = 0.99\n",
    "            print(\"momentum increase on\")\n",
    "            momentum_rate = m_min + (m_max - m_min) * (current_epoch / num_epochs)\n",
    "        else:\n",
    "            momentum_rate = momentum_amount\n",
    "            \n",
    "        #Model Name\n",
    "        model_name = \"ConvNet-CV\" + \"_Best\" + str(i) + str(\"_LRN\") + str(learning_amount) + \"_Epochs\" + str(num_epochs)\n",
    "        model_filename = model_name + \".ckpt\"\n",
    "        model_directory = os.getcwd() + \"/Models5/\" + model_name\n",
    "        model_path = model_directory + \"/\" + model_filename\n",
    "            \n",
    "        # get model\n",
    "        if(use_ConvNet):\n",
    "            with tf.variable_scope(model_name):\n",
    "                model_predictions = createConvNetwork(model_input, model_training)\n",
    "        else:\n",
    "            with tf.variable_scope(model_name):\n",
    "                model_predictions = createSimpleNetwork(model_input)\n",
    "\n",
    "        model_loss = tf.reduce_mean(tf.square(model_predictions - model_output))\n",
    "\n",
    "        if opt == \"MOM\":\n",
    "            print(\"Using Momentum Optimizer\")\n",
    "            model_optimizer = tf.train.MomentumOptimizer(learning_rate, momentum_rate, use_nesterov=True).minimize(model_loss)\n",
    "        elif opt == \"ADAM\":\n",
    "            print(\"Using ADAM Optimizer\")\n",
    "            model_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\n",
    "        else:\n",
    "            print(\"Using SGD Optimizer\")\n",
    "            model_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model_loss)\n",
    "\n",
    "        flip = True\n",
    "\n",
    "        trainModel(train_images1, train_labels1, test_images, test_labels, test_images, test_labels, num_epochs, batch_size, model_name, True, False, False, False)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfolds = 3\n",
    "#kfolds loop\n",
    "#new name\n",
    "#train\n",
    "print(\"hello\")\n",
    "momentum_steps = [0, 1, 2] \n",
    "\n",
    "learning_steps = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "learn_decay = False\n",
    "dropout = False\n",
    "use_ConvNet = False\n",
    "num_epochs = 1000\n",
    "\n",
    "skf = KFold(n_splits=kfolds, random_state=None, shuffle=False)\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(image_values):\n",
    "    print(i)\n",
    "    kfolds2 = 4\n",
    "    momentum_rate = momentum_steps[i]\n",
    "    train_images1 = [image_values[i] for i in train_index]\n",
    "    train_labels1 = [image_labels[i] for i in train_index]\n",
    "    \n",
    "    test_images = [image_values[i] for i in test_index]\n",
    "    test_labels = [image_labels[i] for i in test_index]\n",
    "    j = 0\n",
    "    skf2 = KFold(n_splits=kfolds2, random_state=None, shuffle=False)\n",
    "    for train_index2, valid_index in skf2.split(train_images1):\n",
    "        print(j)\n",
    "        learning_rate = learning_steps[j]\n",
    "        \n",
    "        train_images = np.asarray([train_images1[i] for i in train_index2])\n",
    "        train_labels = np.asarray([train_labels1[i] for i in train_index2])\n",
    "        valid_images = np.asarray([train_images1[i] for i in valid_index])\n",
    "        valid_labels = np.asarray([train_labels1[i] for i in valid_index])\n",
    "                \n",
    "        graph = tf.Graph()\n",
    "        \n",
    "        with graph.as_default():\n",
    "\n",
    "            model_input = tf.placeholder(tf.float32, shape=(None, image_size, image_size, num_channels))\n",
    "            model_output = tf.placeholder(tf.float32, shape=(None, num_classes))\n",
    "            model_training = tf.placeholder(tf.bool)\n",
    "\n",
    "            current_epoch = tf.Variable(0, trainable=False)\n",
    "            #Define Parameters\n",
    "\n",
    "            if learn_decay:\n",
    "                #learning_rate = tf.train.exponential_decay(learning_steps[j], current_epoch, decay_steps=num_epochs, decay_rate=0.03)\n",
    "                learning_rate = tf.train.exponential_decay(\n",
    "                                  learning_steps[j],                # Base learning rate.\n",
    "                                  current_epoch,  # Current index into the dataset.\n",
    "                                  num_epochs,          # Decay step.\n",
    "                                  0.9,                # Decay rate.\n",
    "                                  staircase=True)\n",
    "            else:\n",
    "                learning_rate = learning_steps[j]\n",
    "                print(\"LEARNING RATE:\" + str(learning_rate))\n",
    "\n",
    "            if momentum_inc:\n",
    "                m_min = 0.9\n",
    "                m_max = 0.99\n",
    "                momentum_rate = m_min + (m_max - m_min) * (current_epoch / num_epochs)\n",
    "            else:\n",
    "                momentum = momentum_amount\n",
    "\n",
    "            #Model Name\n",
    "            model_name = \"ConvNet-CV\" + \"_Opt\" + str(i) + str(\"_LRN\") + str(learning_steps[j]) + \"_Epochs\" + str(num_epochs)\n",
    "            model_filename = model_name + \".ckpt\"\n",
    "            model_directory = os.getcwd() + \"/Models5/\" + model_name\n",
    "            model_path = model_directory + \"/\" + model_filename\n",
    "\n",
    "            # get model\n",
    "            if(use_ConvNet):\n",
    "                with tf.variable_scope(model_name):\n",
    "                    model_predictions = createConvNetwork(model_input, model_training)\n",
    "            else:\n",
    "                with tf.variable_scope(model_name):\n",
    "                    model_predictions = createSimpleNetwork(model_input)\n",
    "\n",
    "            model_loss = tf.reduce_mean(tf.square(model_predictions - model_output))\n",
    "\n",
    "            if momentum_steps[i] == 0:\n",
    "                model_optimizer = tf.train.MomentumOptimizer(learning_rate, momentum_rate, use_nesterov=True).minimize(model_loss, global_step = current_epoch)\n",
    "            elif momentum_steps[i] == 1:\n",
    "                model_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(model_loss, global_step = current_epoch)\n",
    "            else:\n",
    "                model_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model_loss, global_step = current_epoch)\n",
    "\n",
    "\n",
    "\n",
    "        trainModel(train_images, train_labels, valid_images, valid_labels, test_images, test_labels, num_epochs, batch_size, model_name, flip, noise, bright, rotate)\n",
    "\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
